{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Redes Neuronales\n",
    "### Aprendizaje Autom치tico - Instituto de Computaci칩n - UdelaR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes Neuronales\n",
    "\n",
    "Supongamos que tenemos una tarea de aprendizaje supervisada donde, a partir de un vector $x^T = (x_1, x_2, \\ldots, x_n)$ con $n$ atributos se busca construir una funci칩n (hip칩tesis) $h_{\\theta}(x): \\mathbb{R}^{n} \\to \\mathbb{R}$ que prediga la salida $y \\in \\mathbb{R}$, a partir de un conjunto de entrenamiento. El problema de aprendizaje para las redes neuronales consiste en aprender los par치metros $\\theta$ a partir de un conjunto de entrenamiento $\\{(x^{(i)},y^{(i)})\\}$ que tiene $m$ elementos y donde cada $(x^{(i)},y^{(i)})$ es una _instancia_ de entrenamiento.  \n",
    "\n",
    "Si la funci칩n de hip칩tesis $h_{\\theta}(x)$ no es lineal, sabemos que podemos utilizar atributos no lineales, resultado de la combinaci칩n de atributos de entrada, y aplicar regresi칩n log칤stica, por ejemplo. El problema con esta aproximaci칩n es que el n칰mero de par치metros crecer치 exponencialmente con la cantidad de atributos, lo que vuelve computacionalmente imposible el problema cuando el n칰mero de atributos es muy grande. Las redes neuronales permiten aprender hip칩tesis complejas de forma eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unidad sigmoide\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/logistic%20unit.PNG\"  alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "Dado un vector de entrada  $x^T = (x_1, x_2, \\ldots, x_n)$, la red neuronal m치s simple que puede construirse es equivalente a la regresi칩n log칤stica, y est치 compuesta por una primera capa de neuronas con los atributos de entrada (a lo que llamaremos _capa de entrada_, y denotaremos tambi칠n como $a^{(1)})$, y una segunda capa compuesta por una sola neurona (o _unidad sigmoide_), que calcula la combinaci칩n lineal de las entradas y le aplica la funci칩n sigmoide (llamada _funci칩n de activaci칩n_), para obtener una salida real. A partir de esta salida, podremos tomar una decisi칩n (por ejemplo, para clasificar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unidad sigmoide\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/logistic%20unit.PNG\"  alt=\"Drawing\" style=\"width: 450px;\"/> \n",
    "$$ x \\in  \\mathbb{R}^{n} = a^{(1)} = \\left[ \\begin{array}{c} x_1\\\\\\vdots\\\\x_n \\end{array}\\right]$$\n",
    "\n",
    "Para esta red de una sola neurona, nuestra funci칩n de hip칩tesis ser치:\n",
    "\n",
    "$$ h_\\theta(x) =  a^{(2)} \\in \\mathbb{R} = g(w^{(1)}\\cdot x + b^{(1)} ) $$\n",
    "\n",
    "siendo $ w^{(1)} = (w_1^{(1)} \\ldots w_n^{(1)}) $ el conjunto de par치metros para la combinaci칩n lineal calculados por la neurona de la capa 2 (tambi칠n llamados _pesos_), $b^{(1)}$ un t칠rmino independiente de sesgo, y $g(z)$ la _funci칩n de activaci칩n_ (en nuestro ejemplo, la funci칩n log칤stica). Obs칠rvese que hemos extendido la definici칩n de $g$ para que reciba un vector y calcule el resultado para cada uno de sus elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes Neuronales\n",
    "\n",
    "Algunas observaciones:\n",
    "\n",
    "* Tanto en las neuronas como en los par치metros, el super칤ndice indica la capa a la que pertenece. Los par치metros con super칤ndice $i$ multiplican a los valores obtenidos en la capa $i$ y el resultado sirve de entrada a la capa $i+1$\n",
    "* El valor de salida de cada neurona $a^{(j)}_i$ se conoce como _activaci칩n_. El valor intermedio $z^{(j)}=b^{(j)} + w^{(j)}\\cdot x$ es conocido tambi칠n como entrada ponderada de la neurona (y veremos m치s adelante la utilidad de identificarla por separado)\n",
    "* En este curso seguiremos la terminolog칤a usual en redes neuronales, llamando $w$ a los par치metros (en lugar de $\\theta$, como hicimos en el m칩dulo de regresi칩n log칤stica). Pero son exactamente los mismos, al igual que el t칠rmino de sesgo.\n",
    "* Una forma alternativa de presentar la combinaci칩n lineal, es definir un par치metro adicional $w_0$ y agregar a $x$ (y a todas las entradas de las neuronas), un valor dummy $1$ al principio, permitiendo incluir el sesgo dentro del producto de los vectores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes Neuronales\n",
    "\n",
    "Las redes neuronales son una generalizaci칩n del ejemplo anterior: en cada una de las capas puede haber m치s de una neurona (que recibe como entrada los resultados de la capa anterior), y pueden introducirse capas intermedias (tambi칠n llamadas _capas ocultas_).\n",
    "\n",
    "Por lo tanto, generalizando el caso anterior tendremos: \n",
    "\n",
    "$$ a^{(1)} \\in  \\mathbb{R}^{n} =  x = \\left[ \\begin{array}{l} x_1\\\\\\vdots\\\\x_n \\end{array}\\right] $$\n",
    "\n",
    "\n",
    "$$ a^{(j)} \\in  \\mathbb{R}^{S_j} =  \\left[ \\begin{array}{l} a^{(j)}_1\\\\\\vdots\\\\a^{(j)}_{s_j} \\end{array}\\right] = g(W^{(j-1)} \\cdot a^{(j-1)} + b^{(j-1)})$$\n",
    "\n",
    "siendo $s_j$ el n칰mero de neuronas en la capa $j$, y $W^{(j)}$ la matriz de pesos que define el mapeo desde la capa $j$ a la capa $j+1$. \n",
    "\n",
    "Este modelo de redes neuronales donde cada capa est치 conectada con la siguiente (y donde, por lo tanto, no existen loops) es conocido como _redes feedforward_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes Neuronales\n",
    "\n",
    "La matriz $W^{(j)}$ tiene en sus filas los pesos asociados a la combinaci칩n lineal de las entradas de la unidad $i$ de la capa $j+1$, que son resultados de la activaci칩n de las unidades en la capa $j$:\n",
    "\n",
    "$$ W^{(j)}= \\left ( \\begin{array} {cccc} \n",
    "w^{(j)}_{11} & w^{(j)}_{12} & \\cdots & w^{(j)}_{1s_{j}}\\\\\n",
    "w^{(j)}_{21} & w^{(j)}_{22} & \\cdots & w^{(j)}_{2s_{j}}\\\\\n",
    "\\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "w^{(j)}_{s_{j+1}1} & w^{(j)}_{s_{j+1}2} & \\cdots & w^{(j)}_{s_{j+1}s_{j}}\\\\\n",
    "\\end{array}\\right )$$\n",
    "\n",
    "Podemos observar que $W^{(j)} \\in  \\mathbb{R}^{s_{j+1}} \\times \\mathbb{R}^{s_{j}}$: tiene tantas filas como neuronas hay en la capa $j+1$, y tantas columnas como neuronas hay en la capa $j$. Cada valor $w^{(j)}_{ik}$ de la matriz debe leerse como el peso asociado a la i-칠sima neurona de la capa $j+1$, correspondiente a la entrada proveniente de la k-칠sima neurona de la capa $j$.\n",
    "\n",
    "De forma similar, el vector de sesgo incluye un componente por cada neurona de la capa anterior:\n",
    "\n",
    "$$ b^{(j)}=  (b^{(j)}_{1}, b^{(j)}_{2}, \\cdots b^{(j)}_{s_{j}})^T $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes Neuronales\n",
    "\n",
    "Supongamos que tenemos una red con dos entradas, y tres unidades en la primera capa oculta. Nuestra matriz de pesos $W^{(1)}$ lucir치 as칤 (eliminamos el supra칤ndice en los componentes para que se vea mejor):\n",
    "\n",
    "$$ W^{(1)} \\in \\mathbb{R^{3 \\times 2}}= \\left ( \\begin{array} {cc} \n",
    "w_{11} & w_{12}\\\\\n",
    "w_{21} & w_{22}\\\\\n",
    "w_{31} & w_{32}\n",
    "\\end{array}\\right )  \\;\\;\n",
    ", \\;\\; b^{(1)} \\in \\mathbb{R^{2 \\times 1}} =  \\left ( \\begin{array} {c} \n",
    "b_{1}\\\\\n",
    "b_{2}\\\\\n",
    "\\end{array}\\right )  $$\n",
    "\n",
    "Si queremos obtener *todos* los valores de $z^{(2)}$:\n",
    "\n",
    "$$ z^{(2)} \\in \\mathbb{R^{3 \\times 1}} = W^{(1)} \\cdot a^{(1)} + b^{(1)} $$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Forward propagation (Propagaci칩n hacia adelante)\n",
    "\n",
    "El proceso de calcular los valores de salida de cada capa, y utilizarlo como entrada para la siguiente, hasta obtener el valor final de $h_\\theta(x)$ es conocido como _forward propagation_. Veremos algunos ejemplos \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Supongamos que tenemos una red neuronal con dos valores de entrada (que supondremos binarios) y queremos construir una red que calcule el OR l칩gico de ambos valores. Para ello, definiremos una arquitectura con dos entradas, y una sola neurona, que nos dar치 la salida necesaria. Comprobaremos que utilizando $W^{(1)} \\in \\mathbb{R}^{2 \\times 1} = ( 20\\  20)$ y $b^{(1)} \\in \\mathbb{R}^{1 \\times 1}=(-10)$ estaremos computando la funci칩n que queremos. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Primero calculamos el resultado de la red para la entrada $x=(0,0)^T$: \n",
    "\n",
    "$$ x \\in  \\mathbb{R}^{2 \\times 1} = a^{(1)} = \\left[ \\begin{array}{c} 0\\\\0\\\\ \\end{array}\\right]$$\n",
    "\n",
    "$$ a^{(2)} \\in  \\mathbb{R}^{1 \\times 1} = g(W^{(1)}\\cdot x + b^{(1)}) = g (20 \\times 0+20 \\times 0-10) = g(-10) \\approx 0$$\n",
    "\n",
    "Es decir que cuando $x_1=0$ y $x_2=0$, entonces $h(x) \\approx 0$, lo cual corresponde a la definici칩n de OR l칩gico. An치logamente, se puede ver que en las otras combinaciones de la entrada, se obtienen los valores adecuados para la funci칩n. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Para ver un caso m치s interesante, construiremos una red neuronal para calcular la funci칩n XNOR, que devuelve $1$ si ambas entradas valen $1$, o ambas entradas valen $0$. Esta funci칩n puede escribirse como OR(AND$(x_1,x_2)$,NOR$(x_1,x_2)$) (comprobarlo), y a partir de esto construiremos una red neuronal de tres capas: las dos neuronas de la primera capa corresponden a las entradas $x_1, x_2$, la segunda capa (oculta), tiene dos neuronas: una computa la funci칩n AND y la otra la funci칩n NOR. Finalmente, la tercera capa (de salida) tiene una sola neurona que computa el OR de los resultados de las neuronas de la capa 2, para obtener el resultado. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "- La entrada ser치 igual que en el caso anterior: $ x \\in  \\mathbb{R}^{2 \\times 1} = a^{(1)} $\n",
    "\n",
    "- En la capa 2, tendremos los par치metros correspondientes a la funci칩n AND en la primera fila (verif칤quelo en cada caso), y a los de NOR en la segunda, lo que nos da la siguiente matriz de par치metros y sesgo\n",
    "\n",
    "$$W^{(1)} \\in  \\mathbb{R}^{2 \\times 2}  = \\left [ \\begin{array}{rr} 20&20\\\\ -20&-20\\\\ \\end{array}\\right], b^{(1)}  \\in \\mathbb{R}^{2 \\times 1}=\\left [ \\begin{array}{r} -30\\\\10\\\\\\end{array}\\right]$$\n",
    "\n",
    "\n",
    "- En la capa 3, hay una sola neurona que calcula el OR de sus entradas:\n",
    "\n",
    "$$W^{(2)}  \\in  \\mathbb{R}^{1 \\times 2} = \\left [ \\begin{array}{rr} 20&20 \\end{array}\\right], b^{(2)}  \\in  \\mathbb{R}^{1 \\times 1}=\\left [ \\begin{array}{r} -10\\\\\\end{array}\\right]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Podemos comprobar mediante forward propagation que nuestra red se comporta como esperamos. Supongamos que las dos entradas son 0: \n",
    "\n",
    "$$ x \\in  \\mathbb{R}^{2 \\times 1} = a^{(1)} = (0,0)^T$$\n",
    "- Obtenemos los valores de activaci칩n de la segunda capa: \n",
    "\n",
    "$$ a^{(2)} \\in  \\mathbb{R}^{2 \\times 1} = g(W^{(1)}\\cdot a^{(1)} + b^{(1)})  = g ((-30\\  20)^T) \\approx (0\\  1)^T$$\n",
    "\n",
    "- El primer valor de $ a^{(2)}$ es $0$, equivalente al AND de las entradas, y el segundo es 1, el NOR de las entradas. \n",
    "\n",
    "- Con estos valores de salida como entrada para la 칯nica neurona de salida, calculamos la activaci칩n: \n",
    "\n",
    "$$ a^{(3)} \\in  \\mathbb{R^{1 \\times 1}} =  g(W^{(2)}\\cdot a^{(2)} + b^{(2)})  = g ((10)) \\approx (1)$$\n",
    "\n",
    "- Por lo tanto, nuestra funci쑕 devuelve $1$ cuando las dos entradas son 0.\n",
    "\n",
    "**Ejercicio: repita el proceso, complete la tabla de valores, y verifique que la red computa la funci칩n XNOR. Verifique que las matrices tienen las dimensiones correctas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje en Redes Neuronales\n",
    "\n",
    "Al igual que en los m칠todos anteriores, es importante entender c칩mo funciona el aprendizaje en redes neuronales. En este caso, lo que intentaremos aprender a partir de los datos de entrenamiento ser치 las matrices de pesos $W^{(j)}$ y $b^{(j)}$ de las diferentes capas. \n",
    "\n",
    "Fijemos algunas definiciones:\n",
    "\n",
    "* $L$ es el n칰mero de capas de la red neuronal\n",
    "* $s_l$ es el n칰mero de neuronas de la capa $l$\n",
    "* $K$ es el n칰mero de neuronas en la capa de salida (por lo tanto, $h_\\Theta(x) \\in \\mathbb{R}^K$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje en Redes Neuronales\n",
    "\n",
    "\n",
    "Una funci칩n de costo para redes neuronales que podemos utilizar es una generalizaci칩n de la funci칩n de m칤nimos cuadrados, que utilizamos para la regresi칩n lineal, pero sumando en todas las unidades de la capa de salida:\n",
    "\n",
    "$$J(W,b) = - \\frac{1}{2m} \\sum_{i=1}^m \\sum_{k=1}^{k=K} (y^{(i)} - a^{(L)}_k)^2 $$\n",
    "\n",
    "\n",
    "Estas funci칩n no es la 칰nica posible. De hecho, basta con suponer que la funci칩n de costo puede escribirse como un promedio de los costos de los ejemplos de entrenamiento, y que puede ser escrita como funci칩n de las salidas de la red. A partir de la primera propiedad, eliminaremos los supra칤ndices en los c치lculos y supondremos que estamos calculando el costo para un ejemplo dado. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura recomendada:  [A list of cost functions used in neural networks, alongside applications](https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje en Redes Neuronales\n",
    "\n",
    "Para aprender los pesos de las redes neuronales, aplicaremos exactamente el mismo procedimiento que utilizamos para la regresi칩n: intentaremos minimizar la funci칩n de costo, utilizando descenso por gradiente. Para ello, necesitaremos calcular las derivadas parciales \n",
    "de $J$ respecto a cada uno de los pesos de la red. Esto es sencillo en el caso de las neuronas de salida, pero un poco m치s complejo en el caso de las unidades ocultas (porque no podemos calcular directamente el error cometido por la neurona).  El algoritmo de backpropagation, precisamente, permite calcular de forma eficiente estas derivadas.\n",
    "\n",
    "Recordemos que la regla de actualizaci칩n (o _regla delta_) en el descenso por gradiente es la siguiente:\n",
    "\n",
    "$$ \\Delta w_{ji} = - \\alpha \\frac{\\partial J}{\\partial w_{ji}} $$\n",
    "\n",
    "donde los $w_{ji}$ son los par치metros asociados a la funci칩n $J$ que queremos minimizar. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation\n",
    "\n",
    "Aplicando la regla de la cadena, podemos ver a la derivada de $J$ en dos partes: \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w^{(l)}_{ji}} =  \\frac{\\partial J}{\\partial z^{(l+1)}_{j}} \\frac{\\partial z^{(l+1)}_j}{ w^{(l)}_{ji}}$$\n",
    "\n",
    "\n",
    "El segundo componente ya lo calculamos en la regresi칩n lineal, y vale $x_{ji}$, es decir el valor de entrada a la neurona $j$, salida de la neurona $i$ de la capa anterior. Al primer componente (que generaliza la idea del \"error\" cometido por la neurona respecto al valor de la instancia de entrenamiento correspondiente), lo llamaremos $\\delta^{(l)}_j$. \n",
    "\n",
    "$$\\delta^{(l)}_j = \\frac{\\partial J  } {\\partial z^{(l)}_j}  $$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Intuitivamente, si incrementamos en $\\Delta z^{(l)}_j$ el valor de la combinaci칩n lineal de la entrada, la salida de la neurona ser치  $g(z^{(l)}_j+\\Delta z^{(l)}_j)$. Este valor se propagar치 por la red, para llegar a un cambio final de $\\frac{\\partial J}{\\partial z^{(l)}_j}  \\Delta z^{(l)}_j$. En caso de que esta derivada final tenga un valor grande, y modifiquemos el valor $\\Delta z^{(l)}_j$ con signo opuesto, podremos reducir el valor de la funci칩n de costo (utilizando descenso por gradiente). Si es el valor de la derivada es cercano a 0, entonces ese par치metro no modifica mucho el costo, por lo que no aporta al costo final (y por lo tanto, es razonable no modificarlo demasiado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation - Neuronas de salida\n",
    "\n",
    "Esta error  puede calcularse directamente para las neuronas de salida, luego de haber calculado los valores de activaci칩n $a^{(L)}$, utilizando nuevamente la regla de la cadena:\n",
    "\n",
    "$$\\delta^{(L)}_j = \\frac{\\partial J} {\\partial a^{(L)}_j} g'(z^{L}_j) $$ \n",
    "\n",
    "En el caso en que J sea la funci칩n de m칤nimos cuadrados y la funci칩n de activaci칩n es la sigmoide, esto es equivalente a:\n",
    "\n",
    "\n",
    "$$\\delta^{(L)}_j = {(a^{(L)}_j - y_j}) \\sigma(z^{L}_j)(1-\\sigma(z^{L}_j) $$ \n",
    "\n",
    "O, en formato vectorial: \n",
    "\n",
    "$$ \\delta^{(L)} = (a^{(L)}-y) \\odot g'(z^{(L)})$$\n",
    "\n",
    "siendo $y$ el valor objetivo de la instancia de entrenamiento, y donde $\\odot$ representa al producto de Hadamard (es decir el producto componente a componente de los vectores involucrados). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* El primer factor est치 relacionado a la derivada de la funci칩n de costo respecto a cada uno de los valores de activaci칩n de la capa de salida (y por lo tanto mide qu칠 tanto cambia el costo como funci칩n del valor de activaci칩n), y el segundo a la derivada de la funci칩n de activaci칩n (es decir, c칩mo est치 cambiando la funci칩n de activaci칩n respecto a su entrada). En el caso de la funci칩n sigmoide, su derivada puede calcularse de forma muy sencilla: $g'(z)=g(z)(1-g(z))$.\n",
    "\n",
    "* Para derivar esta igualdad, considere \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial z_j} = \\frac{\\partial{J}}{\\partial{a_j}} \\frac{\\partial{a_j}}{\\partial{z_j}} $$\n",
    "\n",
    "(Puede encontrar la derivaci칩n en el cap칤tulo 4 de libro de Mitchell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation - Unidades ocultas\n",
    "\n",
    "En el caso de las unidades ocultas, no contamos con el valor \"correcto\", y por lo tanto no podemos calcular directamente el error, sino que debemos hacerlo a partir de los errores de la capa siguiente. Es decir, \"propagaremos hacia atr치s\" el error, intentando calcular c칩mo afecta el valor de salida de cada neurona a las entradas de la capa siguiente. \n",
    "\n",
    "Esto nos lleva a que, si $output(j)$ son los valores de salida de una neurona, entonces:\n",
    "\n",
    "$$\\delta^{(l)}_j = \\sum_{k \\in output(j)} \\delta^{(l+1)}_{k} w^{(l)}_{kj} g'(z^{(l)}_j) $$ \n",
    "\n",
    "\n",
    "Utilizando notaci칩n vectorial: \n",
    "$$ \\delta^{(l)} = (W^{(l)})^T \\delta^{(l+1)} \\odot g'(z^{(l)}) $$\n",
    "\n",
    "siendo $g'(z^{(l)})$ es la derivada de $g$ evaluada en cada uno de los elementos de $z^{(l)}$ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Para derivar esta igualdad, considere \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial z^{(l)}_j} = \\sum_{k \\in output(j)}  \\frac{\\partial{J}}{\\partial{z_k}} \\frac{\\partial{z_k}}{\\partial{a_j}} \\frac{\\partial{a_j}}{\\partial{z_j}} $$\n",
    "\n",
    "(Puede encontrar la derivaci칩n en el cap칤tulo 4 de libro de Mitchell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation - Pesos de sesgo\n",
    "\n",
    "En forma an치loga a los casos anteriores, podemos ver que, en el caso de los pesos independientes, la derivada parcial es exactamente igual a $\\delta$:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial b^{(l)}_j} = \\delta^{(l)}_j $$\n",
    "\n",
    "o, en su versi칩n vectorial\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\delta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Para derivar esta igualdad, considere \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial b^{(l)}_j} = \\sum_{k \\in output(j)}  \\frac{\\partial{J}}{\\partial{z_k}} \\frac{\\partial{z_k}}{\\partial{b_j}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation - C치lculo de derivadas para los pesos \n",
    "\n",
    "\n",
    "Recordemos que: \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w^{(l)}_{ji}} =  \\frac{\\partial J}{\\partial z^{(l+1)}_{j}} \\frac{\\partial z^{(l+1)}_j}{ w^{(l)}_{ji}} $$\n",
    "\n",
    "Entonces:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w^{(l)}_{ji}} = \\delta^{(l+1)}_j  \\frac{\\partial z^{(l)}_j}{ w^{(l)}_{ji}} =  \\delta^{(l+1)}_j a^{(l)}_i $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Obtenidos estos valores, ya podemos aplicar descenso por gradiente para buscar el m칤nimo de la funci칩n de costo. Para cada par치metro, tendremos: $w^{(l)}_{ji} \\leftarrow w^{(l)}_{ji} - \\alpha \\delta^{(l+1)}_j a^{(l)}_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### El algoritmo de backpropagation\n",
    "\n",
    "Resumiendo, el algoritmo de backpropagation permite obtener el m칤nimo de la funci칩n de costo en redes neuronales, calculando primero sus derivadas parciales respecto a cada par치metro de la red. Daremos aqu칤 la versi칩n que utiliza descenso por gradiente incremental. \n",
    "\n",
    "Entradas: \n",
    "- conjunto de entrenamiento $\\{(x^{(1)},y^{(1)}), \\ldots , (x^{(m)},y^{(m)}) \\}$, para cada ejemplo $(x,y)=(x^{(i)},y^{(i)})$\n",
    "- una red neuronal con $n$ entradas, con funci칩n de activaci칩n $g$.\n",
    "- una tasa de aprendizaje $\\alpha$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### El algoritmo de backpropagation\n",
    "\n",
    "Resumiendo, el algoritmo de backpropagation permite obtener el m칤nimo de la funci칩n de costo en redes neuronales, calculando primero sus derivadas parciales respecto a cada par치metro de la red. Daremos aqu칤 la versi칩n que utiliza descenso por gradiente incremental. \n",
    "\n",
    "\n",
    "1. Inicializar los pesos de la red con valores aleatorios peque침os (e.g. entre -.05 y .05)\n",
    "2. Mientras no se cumpla la condici칩n de fin\n",
    "    \n",
    "    2.1. $a^{(1)}$ := $x$\n",
    "    \n",
    "    2.2 Para cada $l=2,3,\\ldots, L$ calcular $z^{(l)}=W^{(l-1)} a^{(l-1)} + b^{(l-1)}$ ; $a^{(l)} = g(z^{(l)})$\n",
    "\n",
    "    2.3. Calcular $\\delta^{(L)} = (a^{(L)}-y) \\odot g'(z^{(L)})$  (suponemos que la funci칩n de costo es m칤nimos cuadrados)\n",
    "\n",
    "    2.4. Propagar el error hacia atr치s: para cada $l = L-1,L-2, \\ldots, 2$ calcular $\\delta^{(l)} = (W^{(l)})^T \\delta^{(l+1)} \\odot g'(z^{(l)})$\n",
    "\n",
    "    2.5 Actualizar los pesos de las capas $l=L,L-1,L-2,\\ldots ,2$:\n",
    "\n",
    "\n",
    "$$ W^{(l)} = W^{(l)} - \\alpha \\delta^{l+1} \\cdot (a^{l})^T$$\n",
    "\n",
    "$$ b^{(l)} = b^{(l)} - \\alpha \\delta^{l}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Video recomendado: [What is backpropagation really doing?](https://www.youtube.com/watch?v=Ilg3gGewQ5U) 3Blue1Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje en Redes Neuronales\n",
    "\n",
    "* El orden para calcular los pesos es desde la 칰ltima capa hacia atr치s, hasta llegar a la segunda capa (la primera capa es la capa de entrada, y por lo tanto no tiene error). \n",
    "\n",
    "* La regla de actualizaci칩n es similar a la regla delta utilizada para regresi칩n lineal: depende de la entrada $x_{ij}$ y del valor del \"error\" de la neurona a la que llegamos. Este error, a su vez, depende de los errores de las capas siguientes, dependiendo de sus respectivos pesos y de c칩mo est치 creciendo la funci칩n de activaci칩n seg칰n la salida de la neurona. \n",
    "\n",
    "* Algunas posibles condiciones de finalizaci칩n:\n",
    "    \n",
    "    - N칰mero de iteraciones\n",
    "    - Accuracy en un conjunto de validaci칩n\n",
    "    - Error en en el conjunto de entrenamiento (Ojo con 游땓)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje en Redes Neuronales\n",
    "\n",
    "* Si la activaci칩n de la neurona es cercana a 0 ( $a^{(l)}_j \\approx 0$),la modificaci칩n en el par치metro al aplicar descenso por gradiente ser치 tambi칠n peque침o. Decimos en este caso que el par치metro est치 _aprendiendo lentamente_.\n",
    "\n",
    "* Cuando una neurona de salida tiene un valor de activaci칩n cercano a 0, o cercano a 1, y dada la forma de la funci칩n sigmoide, tendremos $g'(z_j^{(L)})\\approx0$: el par치metro de esta neurona aprender치 lentamente, y diremos que la neurona est치 _saturada_. Lo mismo puede suceder en las capas anteriores.  Esto hace que en una neurona saturada, los pesos que llegan a esa neurona aprender치n lentamente. \n",
    "\n",
    "* Las ecuaciones que permiten calcular las derivadas parciales dependen de la funci칩n de activaci칩n solamente a trav칠s de su derivada. Por lo tanto, es posible elegir funciones de activaci칩n diferentes para lograr ciertos comportamientos de las redes neuronales.La literatura sobre distintas funciones de activaci칩n y de costo ha sido enorme en los 칰ltimos a침os.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Funciones de activaci칩n \n",
    "\n",
    "- La funci칩n sigmoide no es la 칰nica (y ni siquiera la m치s utilizada) como funci칩n de activaci칩n de las neuronas. Recordemos algunas de sus propiedades:\n",
    "    - Toma valores entre 0 y 1, lo que permite analizar su salida como una probabilidad\n",
    "    - Es diferenciable\n",
    "    - Lleva los valores alejados de la media hacia 0 o 1\n",
    "    \n",
    "<img src=\"https://miro.medium.com/max/1400/1*6A3A_rt4YmumHusvTvVTxw.png\" alt=\"Sigmoide\" style=\"width: 450px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Funciones de activaci칩n \n",
    "\n",
    "- La funci칩n [tangente hiperb칩lica](https://es.wikipedia.org/wiki/Tangente_hiperb%C3%B3lica) es parecida a la sigmoide, con algunas diferencias:\n",
    "    - Toma valores entre $-\\infty$ y $+\\infty$    \n",
    "    - Esto evita el problemas de saturaci칩n en el aprendizaje\n",
    "    - Lleva los valores alejados de la media hacia 0 o 1\n",
    "    - Derivada simple\n",
    "\n",
    "<img src=\"https://www.i2tutorials.com/wp-content/uploads/2019/09/Deep-learning-22-i2tutorials.png\" alt=\"Sigmoide\" style=\"width: 450px;\"/>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Funciones de activaci칩n \n",
    "\n",
    "- La funci칩n ReLU (Rectified Linear Unit) y sus variantes son las m치s populares, especialmente en redes muy grandes, porque permiten aprender m치s r치pido \n",
    "\n",
    "    - Devuelve cero para entradas negativas o cero, y la misma entrada si es positiva, y, Por lo tanto, su rango es de 0 a infinito\n",
    "    - Su principal virtud es que no se satura, porque el gradiente es constante al crecer los valores de z\n",
    "    - Su derivada puede calcularse muy r치pidamente\n",
    "    - Si los valores de activaci칩n son negativos, toma valor 0, lo que es bueno para el aprendizaje\n",
    "    \n",
    "<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/10/Line-Plot-of-Rectified-Linear-Activation-for-Negative-and-Positive-Inputs.png\" alt=\"ReLU\" style=\"width: 400px;\"/>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Recomendado: [What are the advantages of ReLU over sigmoid function in deep neural networks?](https://stats.stackexchange.com/questions/126238/what-are-the-advantages-of-relu-over-sigmoid-function-in-deep-neural-networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clasificaci칩n multiclase y activaci칩n Softmax\n",
    "\n",
    "쮺칩mo podemos utilizar las redes neuronales para clasificar entre m치s de dos clases? \n",
    "\n",
    "La soluci칩n pasa por definir varias neuronas en la capa de salida (podemos observar que el modelo no lo impide), y que la funci칩n $h_\\theta(x)$ devuelva un vector, cuyos elementos sean los valores de activaci칩n de cada una de esas neuronas. \n",
    "Por ejemplo, si tenemos 4 clases posibles de salida, nuestros ejemplos de entrenamiento ser치n:\n",
    "\n",
    "$$ y^{(i)} \\in \\{ \\left[ \\begin{array}{c} 0\\\\0\\\\0\\\\1 \\end{array}\\right], \\left[ \\begin{array}{c} 0\\\\0\\\\1\\\\0 \\end{array}\\right], \\left[ \\begin{array}{c} 0\\\\1\\\\0\\\\0 \\end{array}\\right], \\left[ \\begin{array}{c} 1\\\\0\\\\0\\\\0 \\end{array}\\right] \\}$$\n",
    "\n",
    "Y la misma forma tendr치 $h_\\theta(x)$. Al componente i-esimo de $h_\\theta(x)$ lo denotaremos $(h_\\theta(x))_i$. Si lo que interesa tener es una distribuci칩n de probabilidad entre los valores de las clases, podemos utilizar en la 칰ltima capa una funci칩n de activaci칩n softmax (como vimos en regresi칩n log칤stica): una vez calculados los valores de $z$ de cada neurona de salida, devolvemos\n",
    "\n",
    "$$ \\text{softmax}(z) = \\left [ \\frac{e^{z_1}}{\\sum_{i=1}^k e^{z_i}}, \\frac{e^{z_2}}{\\sum_{i=1}^k e^{z_i}}, \\dots, \\frac{e^{z_k}}{\\sum_{i=1}^k e^{z_i}}  \\right ] $$\n",
    "\n",
    "- Se ha mostrado que la capa softmax tambi칠n evita el problema del enlentencimiento en el aprendizaje (si se utiliza con una funci칩n de costo ligeramente diferente (conocida como log-likelihood)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ejemplo: si en la 칰ltima capa oculta $j$ tenemos valores $(0.7, 0.6)$ para $a^{(j)}$, en la 칰ltima capa tenemos una capa softmax con 4 neuronas, y tenemos una matriz $w^{(j)} \\in \\mathbb{R}^{2\\times4}$ de pesos, el c치lculo queda as칤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.28, 4.83, 0.97, 1.56])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.59690956, 0.38060634, 0.00801861, 0.01446549])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "w=np.array([0.6,8.1,0.3,7.7,0.1,1.5,1.2,1.2]).reshape(4,2)\n",
    "a=np.array([0.7,0.6])\n",
    "\n",
    "z=np.dot(w,a)\n",
    "\n",
    "display(z)\n",
    "np.exp(z)/np.sum(np.exp(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation en la pr치ctica\n",
    "\n",
    "- A diferencia de los casos que vimos en las clases anteriores, la funci칩n de costo de una red neuronal no es convexa, por lo que siempre tenemos el riesgo de que Backpropagation nos lleve a un m칤nimo local. Sin embargo, en la pr치ctica ha mostrado funcionar muy bien. Entender cu치ndo y por qu칠 vamos a quedar en m칤nimos locales no es un problema con una soluci칩n general. Intuitivamente, dado que las redes neuronales tienen muchos par치metros, es m치s dif칤cil que todas las direcciones lleguen a un m칤nimo al mismo tiempo. \n",
    "\n",
    "- Veamos algunas heur칤sticas  para evitar caer en m칤nimos locales.\n",
    "\n",
    "- **Inicializaci칩n de los par치metros**: para evitar que, al aprender, todos los par치metros ajusten al mismo valor, debemos inicializar los par치metros en valores diferentes a 0. Para eso, una soluci칩n es utilizar valores aleatorios entre $[-\\epsilon, \\epsilon]$ para inicializar cada uno de los par치metros. Estos valores deber칤an ser peque침os, para que las funciones hip칩tesis sean m치s suaves al comienzo, y disminuya el riesgo de quedar atrapados en un m칤nimo local. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation en la pr치ctica\n",
    "\n",
    "- **Momentum**: una forma de mejorar la performance del algoritmo  es agregar un componente a la regla de actualizaci칩n que haga que 칠sta dependa parcialmente de la actualizaci칩n anterior. \n",
    "\n",
    " $$\\Delta w_{ji}(n) = \\alpha \\delta^{(l+1)}_j a^{(l)}_{i} + \\Delta w_{ji}(n-1)$$\n",
    " Esto busca favorece el movimiento en el descenso por gradiente en la misma direcci칩n en la que se ven칤a. Esto podr칤a ayudar a superar m칤nimos locales, e incluso favorecer la velocidad de convergencia si el gradiente no est치 cambiando. \n",
    "\n",
    "- **Utilizar SGD**: el descenso por gradiente incremental, al considerar una instancia a la vez, tendr치 diferentes m칤nimos en los gradientes calculados.\n",
    "\n",
    "- **Inicializar con diferentes pesos**: una forma de evitar los m칤nimos locales es intentar ajustar varias veces, utilizando diferentes valores de pesos iniciales, y elegir el mejor en un corpus de validaci칩n separado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient checking\n",
    "\n",
    "Cuando se est치 implementando backpropagation, es muy dif칤cil detectar errores peque침os en el funcionamiento del algoritmo. Una forma mucho m치s sencilla (pero much칤simo m치s lenta) de aproximarse al c치lculo del gradiente es la siguiente: dado un valor peque침o $\\epsilon$ (por ejemplo, $10^{-4}$), calcular:\n",
    "\n",
    "$$   \\frac{\\partial J(W)}{\\partial W} \\approx \\frac{J(W +\\epsilon ) - J(W-\\epsilon )}{2\\epsilon}$$\n",
    "\n",
    "\n",
    "Esta aproximaci칩n nos permite verificar que los valores que estamos calculando con backpropagation de las derivadas son correctos. Por supuesto, esto se utiliza durante el desarrollo del algoritmo: para el ajuste final de los par치metros se desactiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje de Representaciones\n",
    "\n",
    "La redes neuronales tienen la capacidad de aprender representaciones intermedias en las capas ocultas a partir de los datos. Estas representaciones (atributos), que no aparecieron en forma de atributos expl칤citos en la entrada, son sin embargo aprendidas y capturan propiedades de las instancias de entrada. Mostraremos un ejemplo muy sencillo, tomado del libro de Tom Mitchell. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/mitchell_rep_learning.png\" alt=\"Rep.Learning\" style=\"width: 500px;\" />\n",
    "\n",
    "- La red neuronal computa la funci칩n identidad, usando una capa oculta de tres unidades. En la figura puede verse que las capas ocultas est치n aprendiendo la representaci칩n binaria de la entrada (y esto \"comprime\" la representaci칩n de 8 bits a 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje de Representaciones\n",
    "\n",
    " $\\ $           |  $\\ $  \n",
    ":-------------------------:|:-------------------------:\n",
    "![](https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/mitchell_rep_learning2.png) | ![](https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/mitchell_rep_learning3.png)\n",
    "\n",
    "- Podemos ver c칩mo var칤an las activaciones en la capa oculta para la entrada \"01000000\"\n",
    "- Al comienzo, todas las activaciones est치n cercanas a 0.5, y luego se ajustan a los valores (0 1 0)\n",
    "- En la gr치fica de la derecha vemos c칩mo se ajustan los pesos de cada una de las entradas en una de las unidades ocultas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Referencias y material adicional\n",
    "\n",
    "- Machine Learning, Tom Mitchell. Cap칤tulo 4.\n",
    "- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/), Michael Nielsen.\n",
    "- [Notas del curso CS229](http://cs229.stanford.edu/notes/cs229-notes1.pdf) de la Universidad de Stanford (disponible en la plataforma Coursera)\n",
    "- [Calculus on Computational Graphs: Backpropagation](http://colah.github.io/posts/2015-08-Backprop/) Chris Olah\n",
    "\n",
    "Para una excelente visi칩n did치ctica sobre redes neuronales y los algoritmos asociados, recomendamos los [videos](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) de 3Blue1Brown sobre el tema. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
